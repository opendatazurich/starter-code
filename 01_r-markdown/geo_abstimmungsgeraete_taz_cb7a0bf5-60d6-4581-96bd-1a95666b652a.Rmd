---
title: "Open Government Data, OpenDataZurich"
date: "2025-08-31"
output: html_document
---

## Dataset: Abstimmungsgeräte TAZ

Die vom städtischen Tiefbauamt entwickelten Abstimmungsgeräte werden für Befragungen eingesetzt. Ziel ist dabei, ein Stimmungsbild zu einer bestimmten Fragestellung einzuholen. Mit jedem Gerät kann genau eine Frage gestellt werden, die bis zu vier unterschiedliche Antwortmöglichkeiten anbietet. Jedes Drücken einer Taste wird vom Gerät registriert und in 10-Minuten-Intervallen aggregiert. Diese Daten werden drahtlos alle zehn Minuten in eine Datenbank übertragen. Die Rohdaten werden zunächst auf fixe Stundenintervalle aggregiert und anschliessend bereinigt und analysiert. Derzeit werden die Abstimmungsgeräte vor allem für die Befragung der Zufriedenheit mit Piazza Pop-up eingesetzt. Der Datensatz enthält die Standorte und die zugehören aggregierten Endresultate jeder Befragung, vor und nach der Bereinigung.

**Zweck**: Bedürfnisermittlung, Controlling, Wirkungsmessung, allgemeine Planungsgrundlage

**Genereller Hinweis zum Geodatensatz:**


Weitere Informationen zu diesem Datensatz finden sie unter [«**Abstimmungsgeräte TAZ»** auf Geocat.ch](https://www.geocat.ch/geonetwork/srv/ger/catalog.search#/metadata/95c57399-b451-4a5d-89e1-298a43e52924).				
			   

**Datenerfassung:**

Drücken einer Taste wird vom Gerät registriert und in 10-Minuten-Intervallen aggregiert und per LORA-Netzwerk übertragen. Die Rohdaten werden zunächst auf Stundenwerte aggregiert und anschliessend bereinigt.

**Datengrundlage:**

Anzahl der Tastendruck-Vorgänge pro 10-Minuten-Intervall

**Statisches Vorschaubild:**

![BildText](https://www.gis.stadt-zuerich.ch/zueriplan_docs/geocat/95c57399-b451-4a5d-89e1-298a43e52924.png)



[Direct link by **OpenDataZurich** for dataset](https://data.stadt-zuerich.ch/dataset/geo_abstimmungsgeraete_taz)

Auto generated R starter code for data set geo_abstimmungsgeraete_taz.

## Metadata

- **Publisher** `Grundlagen + Strategien, Tiefbauamt, Tiefbau- und Entsorgungsdepartement`
- **Maintainer** `Open Data Zürich`
- **Maintainer_email** `opendata@zuerich.ch`
- **Keywords** `Bevölk­erung,Mobilität,Ver­walt­ung`
- **Tags** `['abstimmungen', 'abstimmungsgerat', 'bedurfnisse', 'bevolkerung', 'einzeldaten', 'geodaten', 'geoportal', 'lora', 'nutzung', 'punktdaten', 'sachdaten', 'stimmungsbilder', 'stzh', 'tabelle', 'zufriedenheit']`
- **Metadata_created** `2023-11-06T03:23:31.742089`
- **Metadata_modified** `2025-08-30T06:39:53.497607`


# Load packages

```{r}
library(httr2)
library(sf)
library(skimr)
library(tidyverse)
library(xml2)
```

# Load the data

data link
```{r}
url <- "https://www.stadt-zuerich.ch/geodaten/download/Abstimmungsgeraete_TAZ?format=geojson_link"
```


Helper function to create the url based on the geoportal, as the files are not directly available via fixed link like csvs.
```{r}
get_geoportal_url <- function(url) {
  dataset_identifier <- sub(".*/(.*)\\?.*", "\\1", url)
  paste0("https://www.ogd.stadt-zuerich.ch/wfs/geoportal/", dataset_identifier)
}
```

```{r}
# Helper function to get available layers from WFS
get_wfs_layers <- function(url) {
  
  url_geoportal <- get_geoportal_url(url)
  
  cat("Getting available layers from:", url_geoportal, "\n")
  
  # read xml from geoportal
  resp <- request(url_geoportal) |> 
    req_headers(service = "WFS", version = "1.1.0", request = "GetCapabilities") |> 
    req_perform()
  
  content_as_xml <- resp_body_xml(resp)
  
  # find available layers: find "Name" nodes with parent "Layer"
  name_nodes <- content_as_xml |> xml_ns_strip() |> xml_find_all("//Name")
  
  # keep all nodes that have Name and it's parent's name is "Layer"
  # and directly extract the name to get a list of typenames
  typename_nodes <- purrr::keep(name_nodes,
                                \(x) xml_name(xml_parent(x)) == "Layer")
  
  return(typename_nodes)
}

# Fetch available layers
layers <- get_wfs_layers(url)

# Set first layer as default
typename <- xml_text(layers[[1]])
cat("Chosen typename:", typename, "\n")
```

read the data
```{r}
read_geodata <- function(url, typename) {
  url_geoportal <- get_geoportal_url(url)
  
  request <- request(url_geoportal) |>
    req_url_query(
      service = "WFS",
      version = "1.1.0",
      outputFormat = "GeoJSON",
      request = "GetFeature",
      typename = typename
    )
  
  st_read(request$url)
}

df <- read_geodata(url, typename)
```

if the approach above does not work, try using [ows4r](https://eblondel.github.io/ows4R/); however, this needs to be installed first
```{r eval=FALSE}
# install.packages("ows4R")
library(ows4R)

# WFS-Client erstellen
url_geoportal <- get_geoportal_url(url)
wfs_client <- WFSClient$new(url_geoportal, "1.1.0")

# Verfügbare Feature-Typen anzeigen
wfs_client$getFeatureTypes(pretty = TRUE)

typenames <- wfs_client$getFeatureTypes(pretty = TRUE) |> 
  dplyr::pull(name)

df <- read_geodata(url, typenames[[1]])
```

# Analyze the data

look at the data
```{r}
head(df)
```

```{r}
glimpse(df)
```

```{r}
# look at distributions etc. without looking at geographical data (skim cannot deal with geometries)
skim(st_drop_geometry(df))
```

# Plot data

base R plot
```{r}
plot(df$geometry)
```

ggplot2 plot
```{r}
df |>
  ggplot() +
  geom_sf()
```

# Continue your code here...

```{r}

```

------------------------------------------------------------------------

# Contact

opendata@zuerich.ch
